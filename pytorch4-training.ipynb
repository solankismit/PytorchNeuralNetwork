{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting The Data and Splitting it into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train = datasets.MNIST(\"\",train=True,transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test = datasets.MNIST(\"\",train=False,transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "trainset = DataLoader(dataset=train,batch_size=10,shuffle=True)\n",
    "testset = DataLoader(dataset=test,batch_size=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    # print(data[0][0].shape)\n",
    "    print(data[0][0].shape)\n",
    "    break\n",
    "# Here We can see Each number is 28*28 pixel thats why we took input of 28*28 in Net. \n",
    "# We will Flat that to single row so that it can be understood by Network. \n",
    "# data[0][0].view(1,28*28) will be used to flatten it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.fc1 = nn.Linear(28*28,64) #fully connected(fc) , nn.Linear(input,output) -->we can choose any number in output, that will be in number of neorons in hidden Layer\n",
    "        self.fc2 = nn.Linear(64,64) # output from the first layer must be input to second\n",
    "        self.fc3 = nn.Linear(64,64)\n",
    "        self.fc4 = nn.Linear(64,10) # Here there is 10 class Classification thats why we have taken 10 as output\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        # Relu -- Rectified Linear Function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        # print(x.shape)\n",
    "        # Why we are not using Relu in last layer?\n",
    "        # Because Relu is used to find the probability of the class.\n",
    "        # In last layer we have to find the probability distribution of the class.\n",
    "        # Softmax is used to find the probability distribution of the class.\n",
    "\n",
    "        return F.log_softmax(x,dim=1)\n",
    "net = Net()\n",
    "print(net) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -1.9254,  -7.7952,  -5.4875,  -7.6779,  -6.9179,  -0.4405,  -1.5912,\n",
       "          -7.2881, -10.0698,  -9.5410]], grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand((28,28))\n",
    "X = X.view(-1,28*28) # Flattening the input, -1 means we dont know how many rows are there but we know there are 28*28 columns\n",
    "output = net(X)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7743, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0320, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0006, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(),lr=0.001) # lr is learning rate, net.parameters() is all the parameters that can be optimized\n",
    "\n",
    "EPOCHS = 3 # How many times we want to go through the data\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        # data is a batch of featuresets and labels\n",
    "        X,y = data # X is the featuresets and y is the labels\n",
    "        # print(X[0])\n",
    "        # print(y[0])\n",
    "        # break\n",
    "        # Everytime we have to set the gradient to zero before we pass the data through the network\n",
    "        net.zero_grad()\n",
    "        X = X.view(-1,28*28)\n",
    "        output = net(X)\n",
    "        loss = F.nll_loss(output, y)\n",
    "        # loss = F.cross_entropy(output,y) # This is same as above line\n",
    "        # Two ways to calculate loss\n",
    "        # 1. F.nll_loss(output, y) --> Negative Log Likelihood Loss\n",
    "        # 2. F.cross_entropy(output,y) --> Cross Entropy Loss\n",
    "        # One hot vector is used in Cross Entropy Loss --> One hot vector is a vector with all zeros and one 1\n",
    "        # Index of the class is used in Negative Log Likelihood Loss\n",
    "\n",
    "        # Difference between F.nll_loss and F.cross_entropy\n",
    "        # F.nll_loss is used when we have only index of the class\n",
    "        # F.cross_entropy is used when we have one hot vector of the class\n",
    "\n",
    "        loss.backward() # Backpropagation\n",
    "        optimizer.step() # Adjust the weights\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.986\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        X,y = data\n",
    "        output =net(X.view(-1,28*28))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct+=1\n",
    "            total+=1\n",
    "\n",
    "print(f\"Accuracy : {round(correct/total,3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ac9c13b650>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X[1].view(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(X[1].view(-1,28*28))))\n",
    "# ArgMax is used to find the index of the maximum value in the tensor\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
